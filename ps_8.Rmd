---
title: "ps_8"
author: "Arnav Srivastava"
date: "4/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading relavent libraries for data analyzing 

library(tidyverse)
library(fivethirtyeight)
library(skimr)
library(broom)
library(gt)

# load tweets dataset from raw-data 

load(file = "raw-data/tweetsnew.Rdata")

# load Trump approval poll

poll <- trump_approval_poll

```

## Question 1: Conduct exploratory data analysis

1a) Summary Statistics
```{r 1a, echo = FALSE}

# summarizing total tweets per week
tweets <- tweets %>% 
  group_by(week) %>% 
  summarize(total_tweets = n())


# determine the poll’s week using the end-date of the survey.

poll$week <- ceiling(as.numeric(difftime(poll$end_date, "2017-01-01", units = "days"))/7)



# joining the tweet data to your poll data using the week variable

twoll <- poll %>% 
  left_join(tweets, by = "week") %>% 
  replace_na(list(total_tweets = 0))



# using skim to show data for 1a

twoll %>%
  select(total_tweets, approve) %>% 
  skim()

```


1B) Bivariate correlations

```{r 1b, echo = FALSE}

# makes missing values for grade explicit so that appears as missing on ggplot,
# then makes scatterplot in the prompt

twoll$grade <- fct_explicit_na(twoll$grade)

ggplot(twoll, aes(x = total_tweets, y = approve, color = grade)) +
  geom_point() +
  theme_classic() +
  labs(title = "Trump Approval Ratings and Number of Tweets",
       subtitle = "Data from fivethirtyeight and Trump Twitter Archive",
       x = "Total Tweets",
       y = "Approval Rating")
  

```


## Question 2: Run a multivariate regression

2A) Using lm()

```{r 2a, echo = FALSE}

# Create a variable “high_q” which takes a value of 1 if the poll is rated A+,
# A, or A-, and 0 if the rating is lower or missing... uses map_dbl to assign
# number and func if_else to see if the correct grade is present

twoll <- twoll %>% 
  mutate(high_q = map_dbl(grade, ~ ifelse(. %in% c("A+", "A", "A-"), 
                                  1, 
                                  0)
                         )
  )



# calculate multivariate regression coefficients for twoll using lm() includng
# conf int with tidy, and then format the table with gt()
# to copy the table, we use parallel slopes model

lm(approve ~ total_tweets + high_q, data = twoll) %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  gt() %>%
  tab_header(title = "Effect of Number of Tweets and Poll Quality on Reported Approval Rating",
             subtitle = "Data from fivethirtyeight and Trump Tweet Archive") %>% 
  cols_label(term = "Variable",
             estimate = "Estimate",
             conf.low = "Lower bound",
             conf.high = "Higher bound")

```


2B) Interpreting results

Given that there are no additional confounding factors for determining the causal factors of approval ratings, we can say that the average treatment effect of raising the approval rating by one point has a decrease in high_q by 0.004. In parallel slope model, high_q rate correlation coefficient is the same as total_tweets, but has a lower intercept than the line for total_tweets. 
The frequentist interpretation for the coefficients states that the confidence intervals contain our true correlation 95% of the time, while the bayesian says that there is a 95% chance that the true correlation is within our confidence interval.


2C) Interaction Variables
```{r 2c, echo = FALSE}

# rerunning our regression, but with an interaction model

lm(approve ~ total_tweets * high_q, data = twoll) %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high) %>% 
  gt() %>%
  tab_header(title = "Effect of Number of Tweets and Poll Quality on Reported Approval Rating",
             subtitle = "Data from fivethirtyeight and Trump Tweet Archive") %>% 
  cols_label(term = "Variable",
             estimate = "Estimate",
             conf.low = "Lower bound",
             conf.high = "Higher bound")


```


2D) Estimating Fitted Values

```{r 2d, echo = FALSE}

# based on our table above, the intercept of a approval vs. high quality poll is
# (41.629177904 - 2.701455717). The slope of this same line is (-0.005586465 +
# 0.020531555). Therefore, plugging intercept for b and slope for m in the
# linear equation y = mx + b, we can approximate the approval rating based on 84
# tweets that week

(-0.005586465 + 0.020531555)*(84) + (41.629177904 - 2.701455717)


# we know compare our value calculated using the fitted value feature of
# augment(), selecting for total_tweets = 84 and high_q polls only, which is the
# criteria we tested our model on. We can slice just slice the first value since
# all fitted values are the same given the criteria we selected for regardless
# of who conducted the poll or when it occurred.

lm(approve ~ total_tweets * high_q, data = twoll) %>% 
  augment() %>% 
  filter(total_tweets == 84 & high_q == 1) %>% 
  slice(1) %>% 
  select(.fitted)

```







Collaborators: None.
